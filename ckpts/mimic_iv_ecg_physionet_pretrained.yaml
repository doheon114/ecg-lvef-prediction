_name: null
common:
  _name: null
  no_progress_bar: false
  log_interval: 10
  log_format: csv
  log_file: null
  wandb_project: null
  wandb_entity: null
  seed: 1
  fp16: false
  memory_efficient_fp16: false
  fp16_no_flatten_grads: false
  fp16_init_scale: 128
  fp16_scale_window: null
  fp16_scale_tolerance: 0.0
  on_cpu_convert_precision: false
  min_loss_scale: 0.0001
  threshold_loss_scale: null
  empty_cache_freq: 0
  all_gather_list_size: 16384
  model_parallel_size: 1
  profile: false
  reset_logging: false
  suppress_crashes: false
common_eval:
  _name: null
  path: null
  quiet: false
  model_overrides: '{}'
  save_outputs: false
  results_path: null
distributed_training:
  _name: null
  distributed_world_size: 4
  distributed_rank: 0
  distributed_backend: nccl
  distributed_init_method: null
  distributed_port: 12355
  device_id: 0
  ddp_comm_hook: none
  bucket_cap_mb: 25
  fix_batches_to_gpus: false
  find_unused_parameters: false
  heartbeat_timeout: -1
  broadcast_buffers: false
  fp16: ${common.fp16}
  memory_efficient_fp16: ${common.memory_efficient_fp16}
dataset:
  _name: null
  num_workers: 10
  skip_invalid_size_inputs_valid_test: false
  max_tokens: null
  batch_size: 64
  required_batch_size_multiple: 8
  data_buffer_size: 10
  train_subset: train
  valid_subset: valid
  combine_valid_subsets: null
  ignore_unused_valid_subsets: false
  validate_interval: 1
  validate_interval_updates: 0
  validate_after_updates: 0
  fixed_validation_seed: null
  disable_validation: false
  max_tokens_valid: ${dataset.max_tokens}
  batch_size_valid: ${dataset.batch_size}
  max_valid_steps: null
  curriculum: 0
  num_shards: 1
  shard_id: 0
optimization:
  _name: null
  max_epoch: 200
  max_update: 0
  lr:
  - 5.0e-05
  stop_time_hours: 0.0
  clip_norm: 0.0
  update_freq:
  - 2
  stop_min_lr: -1.0
checkpoint:
  _name: null
  save_dir: <REDACTED>
  restore_file: checkpoint_last.pt
  finetune_from_model: null
  reset_dataloader: false
  reset_lr_scheduler: false
  reset_meters: false
  reset_optimizer: false
  optimizer_overrides: '{}'
  save_interval: 10
  save_interval_updates: 0
  keep_interval_updates: -1
  keep_interval_updates_pattern: -1
  keep_last_epochs: 0
  keep_best_checkpoints: -1
  no_save: false
  no_epoch_checkpoints: false
  no_last_checkpoints: false
  no_save_optimizer_state: false
  best_checkpoint_metric: loss
  maximize_best_checkpoint_metric: false
  patience: -1
  checkpoint_suffix: ''
  checkpoint_shard_count: 1
  load_checkpoint_on_all_dp_ranks: false
model:
  _name: wav2vec2_cmsc
  apply_mask: true
  mask_prob: 0.65
  encoder_layers: 24
  encoder_embed_dim: 1024
  encoder_ffn_embed_dim: 4096
  encoder_attention_heads: 16
  quantize_targets: true
  final_dim: 256
  dropout_input: 0.1
  dropout_features: 0.1
  feature_grad_mult: 0.1
  in_d: 12
task:
  _name: ecg_pretraining
  data: <REDACTED>/cmsc
  perturbation_mode:
  - random_leads_masking
  p:
  - 1.0
  mask_leads_selection: random
  mask_leads_prob: 0.5
  normalize: false
  enable_padding: true
  enable_padding_leads: false
  leads_to_load: null
criterion:
  _name: wav2vec2_with_cmsc
  infonce: true
  log_keys:
  - prob_perplexity
  - code_perplexity
  - temp
  loss_weights:
  - 0.1
  - 10
lr_scheduler:
  _name: fixed
  warmup_updates: 0
optimizer:
  _name: adam
  adam_betas: (0.9, 0.98)
  adam_eps: 1.0e-06
  weight_decay: 0.01
